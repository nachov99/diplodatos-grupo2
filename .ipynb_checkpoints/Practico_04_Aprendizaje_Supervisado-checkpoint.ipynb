{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e3a8e9-d57f-43bc-8574-cb8b8640cf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f58817-99a9-420e-ba98-8515f8d7b153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opción para ver todas las columnas del dataset en el notebook\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d777221-43e0-4eec-86f9-ecc19f327675",
   "metadata": {},
   "source": [
    "# Práctico 04: Aprendizaje Supervisado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4a8a37-b485-472c-a083-d12e6535641b",
   "metadata": {},
   "source": [
    "Para finalizar nuestro modelo, aplicaremos estrategias de sampling para dividir entre train y test y haremos crossvalidation sobre train. Realizaremos pruebas con varios clasificadores y evaluaremos los resultados con múltiples métricas. Por último calcularemos el feature importance y obtendremos conclusiones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a7e865-52b6-44cf-9304-9bf9f9f8de3c",
   "metadata": {},
   "source": [
    "## Objetivo del práctico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970d7c4a-37e7-49f0-9239-d06e45b3f0aa",
   "metadata": {},
   "source": [
    "### Train-Validation-Test\n",
    "(obtener del práctico anterior)\n",
    "- División del dataset en train/validation/test\n",
    "- Estratificación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2e5dd3-2d30-4466-b791-d592c992867f",
   "metadata": {},
   "source": [
    "### Preprocesamiento\n",
    "(obtener del práctico anterior)\n",
    "- Tratamiento de valores nulos\n",
    "- Estandarización\n",
    "- Encoding de variables categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6d06b3-7f92-486d-89b5-f1e1649a9135",
   "metadata": {},
   "source": [
    "### Definición de métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da00d79-d466-4cd1-a37f-276c213e1953",
   "metadata": {},
   "source": [
    "Definiremos las métricas a utilizar:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1\n",
    "- AUC\n",
    "- PRAUC  \n",
    "\n",
    "Además investigaremos como utilizar el classification report y confusion matrix. Adicionalmente, cómo usar crossvalidation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5ebc3d-05ce-4054-8c85-e0dcdd1ce1c1",
   "metadata": {},
   "source": [
    "### Testeo con varios modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53093eda-08e0-481b-ac08-efb36403f1e0",
   "metadata": {},
   "source": [
    "Realizaremos varios tests con diversos tipos de modelos de scikit-learn:\n",
    "- Logistic regression\n",
    "- SVM\n",
    "- Naive Bayes\n",
    "- etc  \n",
    "Usaremos crossvalidation y compararemos con validation y test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2688ab-1730-4890-899c-ec5c2e1c9310",
   "metadata": {},
   "source": [
    "### Modelos Tree Based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50c78c7-480c-412d-9d54-e509416d2dfc",
   "metadata": {},
   "source": [
    "En esta instancia utilizaremos modelos que no pertenecen a la librería scikit-learn.  \n",
    "Estos modelos son los más utilizados actualmente y han demostrado su efectividad en muchas competencias de Kaggle.  \n",
    "Además, tienen la ventaja de que \n",
    "- XGBoost\n",
    "- LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620ab7fb-fa07-494c-a364-474cdd1a83f0",
   "metadata": {},
   "source": [
    "### Optimización de Hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c52845-e098-46aa-9f9e-84b0249fadb1",
   "metadata": {},
   "source": [
    "En esta sección realizaremos varios tipos de optimización de hiperparámetros para lograr mejorar nuestras métricas.\n",
    "- Grid Search\n",
    "- Randomized Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb35a1b0-18b5-46dd-b6d4-87446b6ebd56",
   "metadata": {},
   "source": [
    "### Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3d29ee-c930-4468-90bb-1ab2467b1b36",
   "metadata": {},
   "source": [
    "Realizaremos feature importance y como opcional utilizaremos la librería SHAP para analizar las predicciones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3f5365-e26a-43ec-a2c3-d32af19f1277",
   "metadata": {},
   "source": [
    "### Presentación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016b43f4-f32c-4633-b9ac-11b588309a40",
   "metadata": {},
   "source": [
    "Al final del práctico, es necesario hacer 3 o 4 slides que irán incluidos en la presentación final.  \n",
    "Los slides deberán contener las etapas de preprocesamiento, los modelos que utilizamos, como optimizamos los hiperparámetros, cómo validamos y qué métricas utilizamos. Por último responderemos desde el punto de vista de negocio si sirve o no sirve el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d816609-1700-4638-a473-f89f92561cd0",
   "metadata": {},
   "source": [
    "### Librerías recomendadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a9029c-0df9-4b15-96f8-fdc0464cd561",
   "metadata": {},
   "source": [
    "Utilizaremos principalmente scikit-learn, opcionalmente xgboost y lightgbm.  \n",
    "Recomiendo el siguiente material:  \n",
    "\n",
    "- https://scikit-learn.org/stable/ -> Referencia de librería scikit-learn. Contiene casi todo lo que vamos a utilizar, pipelines, preprocesamiento y varios modelos.\n",
    "- https://xgboost.readthedocs.io/en/latest/ -> Librería muy utilizada debido a que tiene muy buenos resultados. Es un tipo de algoritmo \"boosting tree\"\n",
    "- https://lightgbm.readthedocs.io/en/latest/ -> Otra librería similar a xgboost, cada vez se usa más, debido a su facilidad de uso y buenos resultados.\n",
    "- https://shap.readthedocs.io/en/latest/index.html -> Librería SHAP, para realizar explainability y analizar predicciones.\n",
    "- https://scikit-learn.org/stable/auto_examples/model_selection/grid_search_text_feature_extraction.html#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py -> Ejemplo de pipelines, cross_validation y optimización de hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aebe6c2-201c-4a50-9a23-5ac2b45e7e65",
   "metadata": {},
   "source": [
    "## Práctico 03: Aprendizaje Supervisado - Resolución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3b1566-2bb9-446e-8f3d-bacbeca84539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos el dataset con la función de pandas \"read_csv\"\n",
    "df = pd.read_csv(\"data/bank-additional-full.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de799ed-8976-4434-8553-33224957c10f",
   "metadata": {},
   "source": [
    "### Train-Validation-Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97553b0f-f1ef-4c12-bde5-f3e732d1510f",
   "metadata": {},
   "source": [
    "(Obtener el código del Práctico 03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344df2e7-a987-473a-8f6b-34c3007433d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazamos la columna y (target) por 1 y 0\n",
    "df.y = df.y.replace('yes', 1)\n",
    "df.y = df.y.replace('no', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3045e7f-3737-4b5f-b545-c6184d173fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1240ad8d-bc6b-4b23-bd33-8a8583bffcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='y')\n",
    "y = df.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9b8474-3bc9-4a3e-8b64-1cbb7b44281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefc61c7-e1a1-4815-8d47-ddec13f8caf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp.shape, y_temp.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69141bd7-4ccd-40ba-a7c2-e7f1a0d1174f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.2, stratify=y_temp, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0030d480-6294-4bea-88a2-0899d94eb622",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b89edf-2da1-4fcb-a03a-7c5d200b4944",
   "metadata": {},
   "source": [
    "### Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507c7144-1ac1-498b-8a86-6addf3815e65",
   "metadata": {},
   "source": [
    "(Obtener el código del Práctico 03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d0eb8c-17af-4abc-a257-0ddf5af9dcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb9d2ea-ac3a-405a-8022-cf7894fdfd69",
   "metadata": {},
   "source": [
    "### Definición de métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7510bd-ea09-4483-8b59-ed43610c5276",
   "metadata": {},
   "source": [
    "Justificar que métricas se utilizarán:  \n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1\n",
    "- AUC\n",
    "- PRAUC  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1572238d-5f4a-4660-abef-e04c1c75b02f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "baedaf93-c007-405d-868e-1ab6cf48ffd2",
   "metadata": {},
   "source": [
    "Explicación de las métricas utilizadas a un stakeholder no técnico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a45511-bd9c-4cdf-9a5d-5266df8de570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Por ejemplo: nuestro modelo identifica a los clientes que adquieren un plazo fijo.\n",
    "# PRECISION: de los clientes que nuestro modelo dicen que van a convertir, precision nos indica el porcentaje que convirtieron realmente.\n",
    "# Si nuestro modelo nos indica que 80 clientes van a convertir y tenemos un precision de 50% esto quiere decir que realmente convierten 40 clientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14981e33-0e84-4406-92d6-c315fef7da36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECALL\n",
    "\n",
    "# Otras métricas que utilizaremos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ff3610-1f1c-483f-aa92-bc08a44b8bf3",
   "metadata": {},
   "source": [
    "### Testeo con varios modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8816b8c1-41d1-47bf-8053-b45e9e31fe7f",
   "metadata": {},
   "source": [
    "Realizaremos varios tests con diversos tipos de modelos de scikit-learn:\n",
    "- Logistic regression\n",
    "- SVM\n",
    "- Naive Bayes\n",
    "- etc  \n",
    "Usaremos crossvalidation y compararemos con validation y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1049b22-fe89-40af-bf04-6de6edc352ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de0e732-6ab0-4e7f-ac8e-b5be297e5757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este es un ejemplo utilizando solo unas pocas columnas y casi sin aplicar transformaciones\n",
    "# Debería realizarse un proceso similar para cada modelo incluyendo todas las columnas y transformaciones\n",
    "# Tener en cuenta de que cada modelo tiene sus particularidades, por ejemplo para modelos lineales es necesario estandarizar variables numéricas,\n",
    "# y además es necesario utilizar one hot encoding para variables categóricas.\n",
    "# En estas situaciones el uso de pipelines nos ayuda a organizar muchísimo nuestro código.\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "variables_numericas = ['cons.price.idx', 'cons.conf.idx', 'age','duration']\n",
    "variables_categoricas = ['education', 'marital','job', 'contact', 'day_of_week']\n",
    "\n",
    "# Filtramos las variables que seleccionamos\n",
    "X_t = X_train[variables_categoricas + variables_numericas]\n",
    "\n",
    "pipeline_numerico = Pipeline([\n",
    "                             ('standard_scaler', StandardScaler()),\n",
    "                            ])\n",
    "\n",
    "pipeline_completo = ColumnTransformer([('num', pipeline_numerico, variables_numericas),\n",
    "                                   ('cat', OneHotEncoder(), variables_categoricas),\n",
    "                                  ])\n",
    "\n",
    "pipeline_modelo = Pipeline([('preprocess', pipeline_completo),\n",
    "                            ('logistic', KNeighborsClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c676027-d5fe-43b5-aa13-f95eb7cd1613",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0497f8d8-e262-45f3-88bf-ad3c6a3156f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para saber la lista de metricas de sklearn:\n",
    "# from sklearn import metrics\n",
    "# list(metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3207f781-66a5-461f-bb20-6a6b5c4d1769",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cross_validate(pipeline_modelo, X_t, y_train, cv=3, scoring=('precision', 'roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bf439f-f50b-4dd4-b866-4429fa6b8321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7da4f159-0806-4754-b8eb-f6e257770bb4",
   "metadata": {},
   "source": [
    "### Modelos Tree Based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4d5a71-ddcc-4474-a785-249917f6e914",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30648f19-9a31-4aa8-9727-881981dafdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar la documentación, utilizar este tipo de modelos no es muy diferente a scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33d3e0d-715b-4238-a529-ce100b0fcd0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a832afa-506d-4213-a9da-a7e570cf6a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este es un ejemplo que utiliza unas pocas features, practicamente sin preprocesamiento. Utilizar como base.\n",
    "import xgboost as xgb\n",
    "variables_numericas = ['cons.price.idx', 'cons.conf.idx', 'age','duration']\n",
    "variables_categoricas = ['education', 'marital','job', 'contact', 'day_of_week']\n",
    "\n",
    "# Filtramos las variables que seleccionamos\n",
    "X_t = X_train[variables_categoricas + variables_numericas]\n",
    "\n",
    "pipeline_numerico = Pipeline([\n",
    "                             ('standard_scaler', StandardScaler()),\n",
    "                            ])\n",
    "\n",
    "pipeline_completo = ColumnTransformer([('num', pipeline_numerico, variables_numericas),\n",
    "                                   ('cat', OneHotEncoder(), variables_categoricas),\n",
    "                                  ])\n",
    "\n",
    "pipeline_modelo = Pipeline([('preprocess', pipeline_completo),\n",
    "                            ('xgb', xgb.XGBClassifier())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb73d60-8626-4a98-bd6f-844f6fb6fef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_modelo.fit(X_t, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d132d1f-5a02-479b-afc8-48dbd9368ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_modelo[1].feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698e0141-048f-41c0-be6b-1aa16c1a2d1d",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164fc844-e114-4007-9ac6-931111515516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar la documentación, utilizar este tipo de modelos no es muy diferente a scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a93a76-1bbc-4ca2-bdb0-d8c0d615a4d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a81ed410-cff9-4585-a15e-9613d7b85e7d",
   "metadata": {},
   "source": [
    "### Optimización de Hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f15e727-5240-4556-a7a0-825fc92559bf",
   "metadata": {},
   "source": [
    "En esta sección realizaremos varios tipos de optimización de hiperparámetros para lograr mejorar nuestras métricas. Elegiremos uno de los modelos (XGBoost o LightGBM) para buscar los parámetros óptimos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b3919f-0088-4fdd-b1f0-c877902550b5",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e3d4c0-9598-4cff-890a-5d589fa30d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto es un ejemplo de optimización de hiperparámetros utilizando un pipeline y un clasificador de XGBoost\n",
    "# Este código no corre en nuestro ejemplo, vamos a tener que modificarlo y adecuarlo\n",
    "# Utilizamos %%time para medir el tiempo del grid search, teniendo cuidado de que si la búsqueda es muy grande puede demorar mucho!!!"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5eed1e46-dfe2-4e3a-a3e8-ff4b3daa868f",
   "metadata": {},
   "source": [
    "model = xgb.XGBClassifier()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('standard_scaler', StandardScaler()), \n",
    "    ('pca', PCA()), \n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'pca__n_components': [5, 10, 15, 20, 25, 30],\n",
    "    'model__max_depth': [2, 3, 5, 7, 10],\n",
    "    'model__n_estimators': [10, 100, 500],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f6bc802f-5322-4fca-bf9d-600c66e62880",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cfcafc79-fc1c-4b8f-85ea-eeaeda6747a3",
   "metadata": {},
   "source": [
    "mean_score = grid.cv_results_[\"mean_test_score\"][grid.best_index_]\n",
    "std_score = grid.cv_results_[\"std_test_score\"][grid.best_index_]\n",
    "\n",
    "grid.best_params_, mean_score, std_score\n",
    "\n",
    "print(f\"Best parameters: {grid.best_params_}\")\n",
    "print(f\"Mean CV score: {mean_score: .6f}\")\n",
    "print(f\"Standard deviation of CV score: {std_score: .6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b721b8d7-8ab9-4393-8a38-5b5e7bae3088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b31dd13-b452-4510-8190-444832751257",
   "metadata": {},
   "source": [
    "#### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4f02f9-db80-450c-b2dc-a8e5d0503112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este ejemplo es muy similar al anterior, y deberíamos lograr unos parámetros parecidos en mucho menos tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210380df-8cbd-44c5-a51c-32debfa32359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90b3a872-0a4c-4394-ac42-8b7b81b9c367",
   "metadata": {},
   "source": [
    "### Feature importance y explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd91fa97-730e-4629-981a-33f186d5eede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "variables_numericas = ['cons.price.idx', 'cons.conf.idx', 'age','duration']\n",
    "variables_categoricas = ['education', 'marital','job', 'contact', 'day_of_week']\n",
    "\n",
    "# Filtramos las variables que seleccionamos\n",
    "X_t = X_train[variables_categoricas + variables_numericas]\n",
    "\n",
    "pipeline_numerico = Pipeline([\n",
    "                             ('standard_scaler', StandardScaler()),\n",
    "                            ])\n",
    "\n",
    "pipeline_completo = ColumnTransformer([('num', pipeline_numerico, variables_numericas),\n",
    "                                   ('cat', OneHotEncoder(), variables_categoricas),\n",
    "                                  ])\n",
    "\n",
    "pipeline_modelo = Pipeline([('preprocess', pipeline_completo),\n",
    "                            ('xgb', xgb.XGBClassifier())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f982a28d-d2c1-4a4f-8e80-01a214a866c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_modelo.fit(X_t, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca8fc63-844f-4edc-91c7-06f97bc34b26",
   "metadata": {},
   "source": [
    "#### Obtener los nombres de las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea53b37-4f39-499b-8258-1178f8a7bd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si realizamos one hot encoding, vamos a tener el problema de que se incrementan el numero de features y necesitamos la nueva lista.\n",
    "numeric_features = variables_numericas\n",
    "cat_features = pipeline_modelo.named_steps['preprocess'].transformers_[1][1].get_feature_names(variables_categoricas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca21edc-c68c-44ef-bf33-7b68a08addf7",
   "metadata": {},
   "source": [
    "#### Feature importance utilizando XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54c8cb8-35d1-438d-bc32-700f215838c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_columns = np.array(cat_features)\n",
    "numeric_features_list = np.array(numeric_features)\n",
    "numeric_features_list = np.append(numeric_features_list, onehot_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d9973b-1100-4005-8953-4fff146f3ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Es necesario ordenar las los valores del feature importance (utilizamos argsort para tener el orden de los indices)\n",
    "sorted_idx = pipeline_modelo[1].feature_importances_.argsort()\n",
    "plt.barh(numeric_features_list[sorted_idx], pipeline_modelo[1].feature_importances_[sorted_idx])\n",
    "plt.xlabel(\"Xgboost Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c2f36d-c63a-4ce1-9c0a-5a629665d93e",
   "metadata": {},
   "source": [
    "#### Feature importance utilizando eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0259e1-cfc5-4695-ac3c-fcd611236c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "# Utilizar eli5 nos resuelve el problema de ordenar las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a27b06-dee4-4a48-a12d-3dc569b7501f",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_columns = cat_features\n",
    "features_list = list(numeric_features)\n",
    "features_list.extend(onehot_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11860d2e-6d4e-40be-9e9d-be8b7a2390af",
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.explain_weights(pipeline_modelo[1], top=50, feature_names=features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7a61bf-0378-4685-9014-d47ae02194c5",
   "metadata": {},
   "source": [
    "#### Utilizar SHAP para obtener feature importance y expainability de las predicciones (opcional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b9f425-b6e2-4b44-a669-27c7b00a2bd1",
   "metadata": {},
   "source": [
    "Como opcional, podemos utilizar la librería SHAP que nos muestra un tipo de explainability por cada predicción. Estas pueden ser agregadas para obtener un feature importance global del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e6bb17-dc5e-46d5-8efb-41d7b32cd795",
   "metadata": {},
   "source": [
    "\n",
    "https://shap.readthedocs.io/en/latest/example_notebooks/tabular_examples/tree_based_models/Census%20income%20classification%20with%20XGBoost.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1223298d-b633-44f1-b517-4a39e74b9a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
